{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charger les données et ajouter une distance au centreVisualisation des clusters sur une carte (Géographique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, sqrt\n",
    "\n",
    "# Initialiser Spark\n",
    "spark = SparkSession.builder.appName(\"AirbnbAnalysis\").getOrCreate()\n",
    "\n",
    "# Charger les données\n",
    "listings = spark.read.csv(\"../Data/cleaned/Data_15_Decembre_2023/listings_detailed_cleaned.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Ajouter une colonne pour la distance au centre-ville (coordonnées exemple : Lyon)\n",
    "center_lat, center_lon = 45.764043, 4.835659\n",
    "listings = listings.withColumn(\n",
    "    \"distance_to_center\",\n",
    "    sqrt((col(\"latitude\") - center_lat)**2 + (col(\"longitude\") - center_lon)**2)\n",
    ")\n",
    "\n",
    "# Ajouter une classification \"centre-ville\" ou \"périphérie\"\n",
    "listings = listings.withColumn(\n",
    "    \"location_category\",\n",
    "    when(col(\"distance_to_center\") < 0.05, \"Centre-Ville\").otherwise(\"Périphérie\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterisation des profils de propriétaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/20 15:29:38 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+----------+\n",
      "|                 id|location_category|prediction|\n",
      "+-------------------+-----------------+----------+\n",
      "|           13652635|     Centre-Ville|         1|\n",
      "|           42535147|     Centre-Ville|         3|\n",
      "|           43736244|     Centre-Ville|         1|\n",
      "|           30554074|     Centre-Ville|         3|\n",
      "|            9474252|     Centre-Ville|         1|\n",
      "|           35566339|     Centre-Ville|         3|\n",
      "|           25907692|     Centre-Ville|         3|\n",
      "|           22070354|     Centre-Ville|         1|\n",
      "|           13368057|     Centre-Ville|         0|\n",
      "| 659360798118676837|     Centre-Ville|         1|\n",
      "|           21627041|     Centre-Ville|         3|\n",
      "|1038321652893112316|     Centre-Ville|         1|\n",
      "|           52204459|     Centre-Ville|         3|\n",
      "|1028705317405886579|     Centre-Ville|         3|\n",
      "|           19059910|     Centre-Ville|         1|\n",
      "| 954491709455745451|     Centre-Ville|         3|\n",
      "| 888929963583097864|     Centre-Ville|         3|\n",
      "|           48266546|     Centre-Ville|         1|\n",
      "|           37413463|     Centre-Ville|         1|\n",
      "|           42008519|     Centre-Ville|         1|\n",
      "+-------------------+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Assembler les colonnes pour la clusterisation\n",
    "feature_cols = [\"distance_to_center\", \"accommodates\", \"bedrooms\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "listings_features = assembler.transform(listings)\n",
    "\n",
    "# Appliquer KMeans\n",
    "kmeans = KMeans(k=4, seed=42)  # 4 clusters\n",
    "model = kmeans.fit(listings_features)\n",
    "listings_clustered = model.transform(listings_features)\n",
    "\n",
    "# Ajouter les clusters au DataFrame\n",
    "listings_clustered.select(\"id\", \"location_category\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation statistique des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "# Convertir les clusters Spark en Pandas pour Folium\n",
    "listings_clustered_pd = listings_clustered.select(\"latitude\", \"longitude\", \"prediction\").toPandas()\n",
    "\n",
    "# Créer une carte centrée sur Lyon\n",
    "m = folium.Map(location=[45.764043, 4.835659], zoom_start=12)\n",
    "\n",
    "# Ajouter des marqueurs pour chaque cluster\n",
    "colors = ['red', 'blue', 'green', 'purple']  # Une couleur par cluster\n",
    "for _, row in listings_clustered_pd.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=5,\n",
    "        color=colors[int(row[\"prediction\"]) % len(colors)],  # Conversion en entier\n",
    "        fill=True,\n",
    "        fill_color=colors[int(row[\"prediction\"]) % len(colors)],  # Conversion en entier\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Cluster: {int(row['prediction'])}\"  # Afficher l'entier dans le popup\n",
    "    ).add_to(m)\n",
    "\n",
    "# Sauvegarder ou afficher la carte\n",
    "m.save(\"cluster_map.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diaggramme en boîte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `price` cannot be resolved. Did you mean one of the following? [`id`, `name`, `source`, `beds`, `latitude`].;\n'Project [distance_to_center#53, accommodates#30, 'price, prediction#230]\n+- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, distance_to_center#53, location_category#74, features#97, UDF(features#97) AS prediction#230]\n   +- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, distance_to_center#53, location_category#74, UDF(struct(distance_to_center, distance_to_center#53, accommodates_double_VectorAssembler_8b099927c0e5, cast(accommodates#30 as double), bedrooms, bedrooms#34)) AS features#97]\n      +- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, distance_to_center#53, CASE WHEN (distance_to_center#53 < 0.05) THEN Centre-Ville ELSE Périphérie END AS location_category#74]\n         +- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, SQRT((POWER((latitude#26 - 45.764043), cast(2 as double)) + POWER((longitude#27 - 4.835659), cast(2 as double)))) AS distance_to_center#53]\n            +- Relation [id#17L,listing_url#18,scrape_id#19L,last_scraped#20,source#21,name#22,picture_url#23,host_id#24,neighbourhood_cleansed#25,latitude#26,longitude#27,property_type#28,room_type#29,accommodates#30,bathrooms_text#31,beds#32,availability_365#33,bedrooms#34] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convertir les données en Pandas pour Seaborn\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m listings_stats_pd \u001b[38;5;241m=\u001b[39m listings_clustered\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance_to_center\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccommodates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Diagramme en boîte des prix par cluster\u001b[39;00m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/BigDataEnv/lib/python3.11/site-packages/pyspark/sql/dataframe.py:3036\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2991\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2992\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m \n\u001b[1;32m   2994\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3036\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jcols(\u001b[38;5;241m*\u001b[39mcols))\n\u001b[1;32m   3037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/anaconda3/envs/BigDataEnv/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/BigDataEnv/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `price` cannot be resolved. Did you mean one of the following? [`id`, `name`, `source`, `beds`, `latitude`].;\n'Project [distance_to_center#53, accommodates#30, 'price, prediction#230]\n+- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, distance_to_center#53, location_category#74, features#97, UDF(features#97) AS prediction#230]\n   +- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, distance_to_center#53, location_category#74, UDF(struct(distance_to_center, distance_to_center#53, accommodates_double_VectorAssembler_8b099927c0e5, cast(accommodates#30 as double), bedrooms, bedrooms#34)) AS features#97]\n      +- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, distance_to_center#53, CASE WHEN (distance_to_center#53 < 0.05) THEN Centre-Ville ELSE Périphérie END AS location_category#74]\n         +- Project [id#17L, listing_url#18, scrape_id#19L, last_scraped#20, source#21, name#22, picture_url#23, host_id#24, neighbourhood_cleansed#25, latitude#26, longitude#27, property_type#28, room_type#29, accommodates#30, bathrooms_text#31, beds#32, availability_365#33, bedrooms#34, SQRT((POWER((latitude#26 - 45.764043), cast(2 as double)) + POWER((longitude#27 - 4.835659), cast(2 as double)))) AS distance_to_center#53]\n            +- Relation [id#17L,listing_url#18,scrape_id#19L,last_scraped#20,source#21,name#22,picture_url#23,host_id#24,neighbourhood_cleansed#25,latitude#26,longitude#27,property_type#28,room_type#29,accommodates#30,bathrooms_text#31,beds#32,availability_365#33,bedrooms#34] csv\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir les données en Pandas pour Seaborn\n",
    "listings_stats_pd = listings_clustered.select(\"distance_to_center\", \"accommodates\", \"price\", \"prediction\").toPandas()\n",
    "\n",
    "# Diagramme en boîte des prix par cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=listings_stats_pd, x=\"prediction\", y=\"price\", palette=\"Set3\")\n",
    "plt.title(\"Distribution des prix par cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Prix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moyennes des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats = listings_clustered.groupBy(\"prediction\").agg(\n",
    "    avg(\"distance_to_center\").alias(\"avg_distance_to_center\"),\n",
    "    avg(\"accommodates\").alias(\"avg_accommodates\"),\n",
    "    avg(\"price\").alias(\"avg_price\")\n",
    ")\n",
    "cluster_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartographie avec clusters et événements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les événements en Pandas\n",
    "events_pd = events.select(\"latitude\", \"longitude\", \"name\", \"date\").toPandas()\n",
    "\n",
    "# Ajouter des marqueurs pour les événements\n",
    "for _, event in events_pd.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[event[\"latitude\"], event[\"longitude\"]],\n",
    "        popup=f\"{event['name']} ({event['date']})\",\n",
    "        icon=folium.Icon(color=\"orange\", icon=\"info-sign\")\n",
    "    ).add_to(m)\n",
    "\n",
    "# Sauvegarder ou afficher la carte enrichie\n",
    "m.save(\"cluster_with_events_map.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse interactive (Slider pour prix ou période)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Tracer une carte interactive avec les clusters\n",
    "fig = px.scatter_mapbox(\n",
    "    listings_clustered_pd,\n",
    "    lat=\"latitude\",\n",
    "    lon=\"longitude\",\n",
    "    color=\"prediction\",\n",
    "    size=\"price\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    title=\"Clusters de logements Airbnb\"\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
